Hacking things on [llama.cpp](https://github.com/ggml-org/llama.cpp) [ Interested in my works? [Buy me a â˜•](https://buymeacoffee.com/ngxson) or [Sponsor me ðŸ©·](https://github.com/sponsors/ngxson) ]

- The brand new `llama-cli`: https://github.com/ggml-org/llama.cpp/pull/17824
- Serving multiple models in parallel via `llama-server`: https://github.com/ggml-org/llama.cpp/pull/17470
- Shipping Ministral 3, Devstral 2 (partnership with Mistral): https://github.com/ggml-org/llama.cpp/pull/17644
- Shipping GPT-OSS (partnership with OpenAI and GGML team): https://github.com/ggml-org/llama.cpp/pull/15091
- Bringing vision support to `llama-server`: https://github.com/ggml-org/llama.cpp/pull/12898 (on [hackernews](https://news.ycombinator.com/item?id=43943047))

<details>
<summary>and more...</summary>

- (Big) refactoring vision support in llama.cpp, introducing `libmtmd`: https://github.com/ggml-org/llama.cpp/pull/12849
- Support various vision models: [Pixtral](https://github.com/ggml-org/llama.cpp/pull/13065), [SmolVLM](https://github.com/ggml-org/llama.cpp/pull/13050), etc (check out this [viral demo](https://x.com/ngxson/status/1921980096421806127))
- Gemma 3 Vision support (partnership with Google): https://github.com/ggml-org/llama.cpp/pull/12343
- WASM speed improvement: https://github.com/ggml-org/llama.cpp/pull/11453 (also checkout [wllama](https://github.com/ngxson/wllama) and [hackernews post](https://news.ycombinator.com/item?id=42852866))
- Refactor argument parser, for a better CLI UX: https://github.com/ggml-org/llama.cpp/pull/9308
- Revamp llama.cpp Web UI (currently deprecated, but was the precursor for the [modern version](https://github.com/ggml-org/llama.cpp/discussions/16938)): https://github.com/ggml-org/llama.cpp/pull/10175
- llama.cpp <> Hugging Face inference endpoint integration: [read docs](https://huggingface.co/docs/inference-endpoints/en/guides/llamacpp_container)
- Hot-swapping LoRA adapters: https://github.com/ggml-org/llama.cpp/pull/8332
- Control vector generator: https://github.com/ggml-org/llama.cpp/pull/7514
- Initial chat template support: https://github.com/ggml-org/llama.cpp/pull/5538

</details>
