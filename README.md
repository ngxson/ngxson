Five bullet points of what I accomplished last week 📅:

- 🐛 Fixed a bug in the `llama_batch_ext` initialization and improved error handling for GPU support in [llama.cpp](https://github.com/ggml-org/llama.cpp).
- 🚀 Created a new branch and added support for async iteration in [wllama](https://github.com/ngxson/wllama).
- 🔍 Reviewed and provided feedback on PRs for improving the Vietnamese translation and documentation in [Agents Course](https://github.com/huggingface/agents-course).
- 🚀 Released a new version (2.3.0) and updated the repository structure for better organization in [wllama](https://github.com/ngxson/wllama).
- 🏃 Investigated and addressed issues related to the `n_predict` parameter and server API behavior in [llama.cpp](https://github.com/ggml-org/llama.cpp).

<sup>This summary is generated by [github-5-bullet-points](https://github.com/ngxson/github-5-bullet-points) 🤖</sup>