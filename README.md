Five bullet points of what I accomplished last week 📅:

- 🐛 Fixed a bug in the `clip.cpp` file to restore GPU support for vision models in [llama.cpp](https://github.com/ggml-org/llama.cpp).
- 🚀 Added support for multimodal models like Phi-4 in [llama.cpp](https://github.com/ggml-org/llama.cpp).
- 🔍 Reviewed and improved the performance of the `llama_batch_ext` system in [llama.cpp](https://github.com/ggml-org/llama.cpp).
- 📝 Updated documentation and examples for better user experience in [huggingface.js](https://github.com/huggingface/huggingface.js).
- 🏃 Investigated and resolved issues related to model context limits and server performance in [llama.cpp](https://github.com/ggml-org/llama.cpp).

<sup>This summary is generated by [github-5-bullet-points](https://github.com/ngxson/github-5-bullet-points) 🤖</sup>