Five bullet points of what I accomplished last week ğŸ“…:

- ğŸ› Fixed a bug in the `clip.cpp` file to restore GPU support for vision models in [llama.cpp](https://github.com/ggml-org/llama.cpp).
- ğŸš€ Added support for multimodal models like Phi-4 in [llama.cpp](https://github.com/ggml-org/llama.cpp).
- ğŸ” Reviewed and improved the performance of the `llama_batch_ext` system in [llama.cpp](https://github.com/ggml-org/llama.cpp).
- ğŸ“ Updated documentation and examples for better user experience in [huggingface.js](https://github.com/huggingface/huggingface.js).
- ğŸƒ Investigated and resolved issues related to model context limits and server performance in [llama.cpp](https://github.com/ggml-org/llama.cpp).

<sup>This summary is generated by [github-5-bullet-points](https://github.com/ngxson/github-5-bullet-points) ğŸ¤–</sup>